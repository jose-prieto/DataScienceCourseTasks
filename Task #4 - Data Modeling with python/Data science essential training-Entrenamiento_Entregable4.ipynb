{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de regresión para la predicción de precios de automóviles\n",
    "## Data science essential training\n",
    "### DiplomadosOnline.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute las siguientes lineas para continuar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - (n_val + n_test)\n",
    "\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "df_shuffled = df.iloc[idx]\n",
    "\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train+n_val:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_orig = df_train.msrp.values\n",
    "y_val_orig = df_val.msrp.values\n",
    "y_test_orig = df_test.msrp.values\n",
    "\n",
    "y_train = np.log1p(df_train.msrp.values)\n",
    "y_val = np.log1p(df_val.msrp.values)\n",
    "y_test = np.log1p(df_test.msrp.values)\n",
    "\n",
    "del df_train['msrp']\n",
    "del df_val['msrp']\n",
    "del df_test['msrp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 ) Modelado de los datos \n",
    "\n",
    "Tras realizar el análisis inicial de los datos, estamos preparados para entrenar un modelo. El problema que estamos resolviendo es un problema de regresión: el objetivo es predecir un número, el precio de un automovil.\n",
    "\n",
    "Para este proyecto utilizaremos el modelo de regresión más sencillo: la regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Regresión lineal\n",
    "\n",
    "En primer lugar, repasemos cómo funciona la regresión lineal.\n",
    "\n",
    "<img src=\"regresion.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos una observación simple $x_{i}$ y el valor y $i$ que queremos predecir. El ı́ndice $i$ significa aquı́ que se trata de la observación número $i$, una de las $m$ observaciones que tenemos en nuestro conjunto de datos de entrenamiento.\n",
    "\n",
    "Entonces, para esta única observación, el modelo a estimar tiene la forma:\n",
    "\n",
    "$y_{i} \\approx f(x_{i})$\n",
    "\n",
    "Si tenemos $n$ caracterı́sticas, nuestro vector $x_{i}$ serı́a $n−$dimensional, por lo que tiene $n$ componentes:\n",
    "\n",
    "$x_{i} = (x_{i1},x_{i2},..., x_{in})$\n",
    "\n",
    "Como tiene $n$ componentes, podemos escribir la función $f$ como una función con $n$ parámetros, que es lo mismo que la fórmula anterior:\n",
    "\n",
    "$y_{i} \\approx f(x_{i}) = f(x_{i1},x_{i2},..., x_{in})$\n",
    "\n",
    "En nuestro caso, tenemos $7,150$ autos en el conjunto de datos de entrenamiento. Esto significa que $m = 7,150$ y $i$ puede ser cualquier número entre 0 y 7,149.\n",
    "\n",
    "Si $f$ es el modelo de regresión lineal, tiene la siguiente forma:\n",
    "\n",
    "$f(x_{i}) = f(x_{i1},x_{i2},..., x_{in})=\\beta_{0}+\\beta_{1}x_{i1}+\\cdots+\\beta_{n}x_{in}$\n",
    "\n",
    "donde, $\\beta_{0},..., \\beta_{n}$ son los parámetros del modelo:\n",
    "\n",
    "- $\\beta_{0}$ es el término de sesgo \n",
    "\n",
    "\n",
    "- $\\beta_{1},...,\\beta_{n}$ son las ponderaciones de cada caracterı́stica $x_{i1},x_{i2},..., x_{in}$.\n",
    "\n",
    "Estos parámetros definen exactamente cómo debe combinar el modelo las caracterı́sticas para que las predicciones al final sean lo mejor posible.\n",
    "\n",
    "Para que la fórmula sea más corta, vamos a utilizar la notación de suma:\n",
    "\n",
    "$f(x_{i}) = f(x_{i1},x_{i2},..., x_{in})=\\beta_{0}+ \\sum_{j=1}^{n}\\beta_{j}x_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento:**\n",
    "\n",
    "¿Cuáles son $x_{i}$ e $y_{i}$ para este problema?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas ponderaciones son las que aprende el modelo cuando lo entrenamos.\n",
    "\n",
    "Este modelo lo podemos escribir es forma matricial como:\n",
    "\n",
    "$f(X) = \\beta_{0} + X β ,$\n",
    "\n",
    "donde, $\\beta$ es el vector columna de los coeficientes $\\beta_{1} , \\beta_{2} , ..., \\beta_{n}$ , mientras $X$ es lo que se conoce como la matiz de diseño que contiene todas las observaciones de las caracterı́sticas consideradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Entrenamiento del modelo de regresión\n",
    "\n",
    "Para poder hacer prediciones, necesitamos saber las ponderaciones $\\beta$. ¿Cómo las obtenemos?\n",
    "\n",
    "Aprendemos los pesos a partir de los datos: utilizamos la variable objetivo $y$ para encontrar la beta que combina las caracterı́sticas de $X$ de la mejor manera posible.\n",
    "\n",
    "En el caso de la regresión lineal, “la mejor manera posible ”significa que minimiza el error entre las predicciones $f(X)$ y el objetivo real $y$.\n",
    "\n",
    "Tenemos varias formas de hacerlo. Utilizaremos la ecuación normal, que es el método más sencillo. El vector de pesos $\\beta$ se puede calcular con la siguiente fórmula:\n",
    "\n",
    "$\\beta = (X^{T}X)^{−1} X^{T}y$\n",
    "\n",
    "Esto es fácil de traducir a NumPy:\n",
    "\n",
    "- $X^{T}$ es la transpuesta de $X$. En NumPy, es `X.T`\n",
    "\n",
    "\n",
    "- $X^{T}X$ es una multiplicación de matrices, que podemos hacer con el método del punto de NumPy: `X.T.dot(X)`\n",
    "\n",
    "\n",
    "- $X^{−1}$ es la inversa de X. Podemos utilizar la función `np.linalg.inv` para calcular la inversa.\n",
    "\n",
    "\n",
    "Para implementar la ecuación normal, tenemos que hacer lo siguiente:\n",
    "\n",
    "- Crear una función que tome una matriz $X$ con caracterı́sticas y un vector $y$ con el objetivo.\n",
    "\n",
    "\n",
    "- Añadir una columna ficticia (la caracterı́stica que siempre se pone en 1) a la matriz $X$.\n",
    "\n",
    "\n",
    "- Entrena el modelo: calcula los pesos $\\beta$ mediante la ecuación normal.\n",
    "\n",
    "\n",
    "- Dividir este $\\beta$ en el sesgo $\\beta_{0}$ y el resto de los pesos, y devolverlos.\n",
    "\n",
    "\n",
    "- El último paso (dividir $\\beta$ en el término de sesgo y el resto) es opcional y se hace principalmente por conveniencia.\n",
    "\n",
    "\n",
    "La implementación serı́a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w[0], w[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento:**\n",
    "\n",
    "Explique cada función e identifı́quela con los pasos señalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
